{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Printing out a bunch of stuff using:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FIGURE_out_sparse():\n",
      "\tprint \"train:\",train\n",
      "\tprint \"train[0]:\",train[0]\n",
      "\tprint \"train[:,0]:\",train[:,0]\n",
      "\tprint \"train[1]:\",train[1]\n",
      "\tprint \"train[:,1]:\",train[:,1]\n",
      "\tprint \"train[2]:\",train[2]\n",
      "\tprint \"train[:,2]:\",train[:,2]\n",
      "\tprint \"train[0, 67869]:\",train[0, 67869]\n",
      "\tprint \"train[234, 1]:\",train[234, 1]\n",
      "FIGURE_out_sparse()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python runMe_kiri_2013-12-13.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train:   (0, 67869)\t0.107145497312\n",
        "  (0, 63252)\t0.321771785737\n",
        "  (0, 57224)\t0.530643672851\n",
        "  (0, 31459)\t0.679529554677\n",
        "  (0, 1692)\t0.376350417952\n",
        "  (1, 67870)\t0.114852716905\n",
        "  (1, 44617)\t0.574361576672\n",
        "  (1, 34509)\t0.810504554375\n",
        "  (2, 67870)\t0.126871043579\n",
        "  (2, 43446)\t0.829394229018\n",
        "  (2, 37779)\t0.544067046579\n",
        "  (3, 67870)\t0.148437399415\n",
        "  (3, 42315)\t0.756815092461\n",
        "  (3, 37779)\t0.6365510618\n",
        "  (4, 67869)\t0.115783626878\n",
        "  (4, 57217)\t0.428751599371\n",
        "  (4, 57009)\t0.367228053551\n",
        "  (4, 17823)\t0.708880380116\n",
        "  (4, 1692)\t0.406691997899\n",
        "  (5, 67870)\t0.118973827025\n",
        "  (5, 44621)\t0.605702060738\n",
        "  (5, 4531)\t0.786746618741\n",
        "  (6, 67869)\t0.0884038385083\n",
        "  (6, 57011)\t0.516783813987\n",
        "  (6, 55155)\t0.560667713721\n",
        "  :\t:\n",
        "  (89299, 24439)\t0.684832428154\n",
        "  (89300, 67869)\t0.127726221459\n",
        "  (89300, 12217)\t0.781998412558\n",
        "  (89300, 2534)\t0.610052862553\n",
        "  (89301, 67870)\t0.0954760890391\n",
        "  (89301, 41829)\t0.716169648697\n",
        "  (89301, 12217)\t0.691364846305\n",
        "  (89302, 67878)\t0.171716222275\n",
        "  (89302, 67869)\t0.0931176048192\n",
        "  (89302, 67005)\t0.435789896991\n",
        "  (89302, 51339)\t0.514687271332\n",
        "  (89302, 48135)\t0.319514940752\n",
        "  (89302, 8042)\t0.590562983261\n",
        "  (89302, 393)\t0.237007161341\n",
        "  (89303, 67878)\t0.174631230151\n",
        "  (89303, 67869)\t0.0946983439471\n",
        "  (89303, 65433)\t0.600588219809\n",
        "  (89303, 63252)\t0.284391374371\n",
        "  (89303, 53243)\t0.33848241691\n",
        "  (89303, 31319)\t0.600588219809\n",
        "  (89303, 1835)\t0.208985495164\n",
        "  (89304, 67871)\t0.358921225487\n",
        "  (89304, 67869)\t0.103423856993\n",
        "  (89304, 2657)\t0.655926466801\n",
        "  (89304, 0)\t0.655926466801\n",
        "train[0]:   (0, 67869)\t0.107145497312\n",
        "  (0, 63252)\t0.321771785737\n",
        "  (0, 57224)\t0.530643672851\n",
        "  (0, 31459)\t0.679529554677\n",
        "  (0, 1692)\t0.376350417952\n",
        "train[:,0]:   (89304, 0)\t0.655926466801\n",
        "train[1]:   (0, 67870)\t0.114852716905\n",
        "  (0, 44617)\t0.574361576672\n",
        "  (0, 34509)\t0.810504554375\n",
        "train[:,1]:   (229, 0)\t0.649829786102\n",
        "  (230, 0)\t0.683669080937\n",
        "  (231, 0)\t0.58403570412\n",
        "  (232, 0)\t0.623985520334\n",
        "  (234, 0)\t0.326850722219\n",
        "  (830, 0)\t0.649829786102\n",
        "  (831, 0)\t0.683669080937\n",
        "  (832, 0)\t0.58403570412\n",
        "  (833, 0)\t0.623985520334\n",
        "  (835, 0)\t0.326850722219\n",
        "  (866, 0)\t0.389217208269\n",
        "  (1904, 0)\t0.676775324382\n",
        "  (1993, 0)\t0.54777137069\n",
        "  (2026, 0)\t0.54607404294\n",
        "  (2200, 0)\t0.649829786102\n",
        "  (2201, 0)\t0.683669080937\n",
        "  (2202, 0)\t0.58403570412\n",
        "  (2203, 0)\t0.623985520334\n",
        "  (2205, 0)\t0.326850722219\n",
        "  (3039, 0)\t0.58845337653\n",
        "  (3048, 0)\t0.578322484338\n",
        "  (3355, 0)\t0.649829786102\n",
        "  (3356, 0)\t0.683669080937\n",
        "  (3358, 0)\t0.326850722219\n",
        "  (3769, 0)\t0.649829786102\n",
        "  :\t:\n",
        "  (86401, 0)\t0.623985520334\n",
        "  (86403, 0)\t0.326850722219\n",
        "  (86522, 0)\t0.465943719013\n",
        "  (86893, 0)\t0.336579198055\n",
        "  (86895, 0)\t0.270399831894\n",
        "  (87191, 0)\t0.649829786102\n",
        "  (87192, 0)\t0.683669080937\n",
        "  (87193, 0)\t0.623985520334\n",
        "  (87195, 0)\t0.326850722219\n",
        "  (88320, 0)\t0.649829786102\n",
        "  (88321, 0)\t0.683669080937\n",
        "  (88322, 0)\t0.623985520334\n",
        "  (88324, 0)\t0.326850722219\n",
        "  (88648, 0)\t0.461594084409\n",
        "  (88824, 0)\t0.649829786102\n",
        "  (88825, 0)\t0.683669080937\n",
        "  (88826, 0)\t0.623985520334\n",
        "  (88828, 0)\t0.326850722219\n",
        "  (89179, 0)\t0.649829786102\n",
        "  (89180, 0)\t0.683669080937\n",
        "  (89181, 0)\t0.623985520334\n",
        "  (89182, 0)\t0.326850722219\n",
        "  (89212, 0)\t0.345809151579\n",
        "  (89246, 0)\t0.574728161327\n",
        "  (89247, 0)\t0.521103465061\n",
        "train[2]:   (0, 67870)\t0.126871043579\n",
        "  (0, 43446)\t0.829394229018\n",
        "  (0, 37779)\t0.544067046579\n",
        "train[:,2]:   (38548, 0)\t0.702752363771\n",
        "train[0, 67869]: 0.107145497312\n",
        "train[234, 1]: 0.326850722219\n",
        "vectorizer finished for split_var @  train/test shapes are:\n",
        "(89305, 68008) (877, 68008)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Why are the values not all 1?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "I think the values should all either be 0 or 1!"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "ANS: This is because using TfidfVectorizer.  Switched to CountVectorizer\n",
      "\n",
      "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "# vectorizer = TfidfVectorizer(min_df = 1, tokenizer=splitter)\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "vectorizer = CountVectorizer(min_df = 1, tokenizer=splitter)\n",
      "train = vectorizer.fit_transform(train2).tocsr()\n",
      "test = vectorizer.transform(test2).tocsr()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python runMe_2014-01-16-BK.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BOO\n",
        "train:   (0, 1692)\t1\n",
        "  (0, 31459)\t1\n",
        "  (0, 57224)\t1\n",
        "  (0, 63252)\t1\n",
        "  (0, 67869)\t1\n",
        "  (1, 34509)\t1\n",
        "  (1, 44617)\t1\n",
        "  (1, 67870)\t1\n",
        "  (2, 37779)\t1\n",
        "  (2, 43446)\t1\n",
        "  (2, 67870)\t1\n",
        "  (3, 37779)\t1\n",
        "  (3, 42315)\t1\n",
        "  (3, 67870)\t1\n",
        "  (4, 1692)\t1\n",
        "  (4, 17823)\t1\n",
        "  (4, 57009)\t1\n",
        "  (4, 57217)\t1\n",
        "  (4, 67869)\t1\n",
        "  (5, 4531)\t1\n",
        "  (5, 44621)\t1\n",
        "  (5, 67870)\t1\n",
        "  (6, 1692)\t1\n",
        "  (6, 18048)\t1\n",
        "  (6, 55155)\t1\n",
        "  :\t:\n",
        "  (89299, 67870)\t1\n",
        "  (89300, 2534)\t1\n",
        "  (89300, 12217)\t1\n",
        "  (89300, 67869)\t1\n",
        "  (89301, 12217)\t1\n",
        "  (89301, 41829)\t1\n",
        "  (89301, 67870)\t1\n",
        "  (89302, 393)\t1\n",
        "  (89302, 8042)\t1\n",
        "  (89302, 48135)\t1\n",
        "  (89302, 51339)\t1\n",
        "  (89302, 67005)\t1\n",
        "  (89302, 67869)\t1\n",
        "  (89302, 67878)\t1\n",
        "  (89303, 1835)\t1\n",
        "  (89303, 31319)\t1\n",
        "  (89303, 53243)\t1\n",
        "  (89303, 63252)\t1\n",
        "  (89303, 65433)\t1\n",
        "  (89303, 67869)\t1\n",
        "  (89303, 67878)\t1\n",
        "  (89304, 0)\t1\n",
        "  (89304, 2657)\t1\n",
        "  (89304, 67869)\t1\n",
        "  (89304, 67871)\t1\n",
        "train[0]:   (0, 1692)\t1\n",
        "  (0, 31459)\t1\n",
        "  (0, 57224)\t1\n",
        "  (0, 63252)\t1\n",
        "  (0, 67869)\t1\n",
        "train[:,0]:   (89304, 0)\t1\n",
        "train[1]:   (0, 34509)\t1\n",
        "  (0, 44617)\t1\n",
        "  (0, 67870)\t1\n",
        "train[:,1]:   (229, 0)\t1\n",
        "  (230, 0)\t1\n",
        "  (231, 0)\t1\n",
        "  (232, 0)\t1\n",
        "  (234, 0)\t1\n",
        "  (830, 0)\t1\n",
        "  (831, 0)\t1\n",
        "  (832, 0)\t1\n",
        "  (833, 0)\t1\n",
        "  (835, 0)\t1\n",
        "  (866, 0)\t1\n",
        "  (1904, 0)\t1\n",
        "  (1993, 0)\t1\n",
        "  (2026, 0)\t1\n",
        "  (2200, 0)\t1\n",
        "  (2201, 0)\t1\n",
        "  (2202, 0)\t1\n",
        "  (2203, 0)\t1\n",
        "  (2205, 0)\t1\n",
        "  (3039, 0)\t1\n",
        "  (3048, 0)\t1\n",
        "  (3355, 0)\t1\n",
        "  (3356, 0)\t1\n",
        "  (3358, 0)\t1\n",
        "  (3769, 0)\t1\n",
        "  :\t:\n",
        "  (86401, 0)\t1\n",
        "  (86403, 0)\t1\n",
        "  (86522, 0)\t1\n",
        "  (86893, 0)\t1\n",
        "  (86895, 0)\t1\n",
        "  (87191, 0)\t1\n",
        "  (87192, 0)\t1\n",
        "  (87193, 0)\t1\n",
        "  (87195, 0)\t1\n",
        "  (88320, 0)\t1\n",
        "  (88321, 0)\t1\n",
        "  (88322, 0)\t1\n",
        "  (88324, 0)\t1\n",
        "  (88648, 0)\t1\n",
        "  (88824, 0)\t1\n",
        "  (88825, 0)\t1\n",
        "  (88826, 0)\t1\n",
        "  (88828, 0)\t1\n",
        "  (89179, 0)\t1\n",
        "  (89180, 0)\t1\n",
        "  (89181, 0)\t1\n",
        "  (89182, 0)\t1\n",
        "  (89212, 0)\t1\n",
        "  (89246, 0)\t1\n",
        "  (89247, 0)\t1\n",
        "train[2]:   (0, 37779)\t1\n",
        "  (0, 43446)\t1\n",
        "  (0, 67870)\t1\n",
        "train[:,2]:   (38548, 0)\t1\n",
        "train[0, 67869]: 1\n",
        "train[234, 1]: 1\n",
        "vectorizer finished for split_var @  train/test shapes are:\n",
        "(89305, 68008) (877, 68008)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This fixes it - yay!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "How frequent are the features?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Features of frequency 1 can't contribute to better self-training, though they could be useful in the end for test-set predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python runMe_2014-01-16-BK.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the frequencies are:  <numpy.flatiter object at 0x0000000015B254F0>\n",
        "len(freqs) =  68008\n",
        "num 1s:  43010\n",
        "vectorizer finished for split_var @  train/test shapes are:\n",
        "(89305, 68008) (877, 68008)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "CONCLUSION: About 2/3 of all elements occur only once!\n",
      "\n",
      "Going to eliminate the very infrequent elements:\n",
      "vectorizer = CountVectorizer(min_df = 2, tokenizer=splitter)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python runMe_2014-01-16-BK.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the frequencies are:  <numpy.flatiter object at 0x00000000167AFE80>\n",
        "len(freqs) =  24998\n",
        "num 1s:  0\n",
        "vectorizer finished for split_var @  train/test shapes are:\n",
        "(89305, 24998) (877, 24998)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "What is linear_model.SGDClassifier?  Is this what we should be using?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "It implements Stochastic Gradient Descent.\n",
      "The code sets loss='log':\n",
      "    clf = linear_model.SGDClassifier(loss='log')\n",
      "This causes this to do logistic regression:\n",
      "    The loss function to be used. Defaults to \u2018hinge\u2019, which gives \n",
      "    a linear SVM. The \u2018log\u2019 loss gives logistic regression\n",
      "    http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
      "\n",
      "An alternative would be to use sklearn.linear_model.LogisticRegression\n",
      "    http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "SGD"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#linear_model.SGDClassifier(loss='log'):\n",
      "!python runMe_2014-01-16-BK.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the frequencies are:  <numpy.flatiter object at 0x000000001664D230>\n",
        "len(freqs) =  24998\n",
        "num 1s:  0\n",
        "vectorizer finished for split_var @  train/test shapes are:\n",
        "(89305, 24998) (877, 24998)\n",
        "SGD training score  1.0\n",
        "SGD test score  0.533637400228\n",
        "SGD training score iter  1 0.92000593648\n",
        "SGD test score iter  1 0.0877993158495\n",
        "SGD training score iter  2 0.947472146016\n",
        "SGD test score iter  2 0.0490307867731\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Why is the first train/test scores different?\n",
      "Why did the test score go down so much?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}